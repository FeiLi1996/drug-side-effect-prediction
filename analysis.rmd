
# Acute Kidney Injury
## About Acute Kidney Injury

Acute Kidney Injury(AKI) is described as a sudden decrease in kidney function relative to its normal function. It can range from partial function reduction to complete loss in function. Prolonged AKI can lead to kidney failure. AKI also complicates treatment processes of a variety of drugs since they  rely on the kidney for removal.
Research has shown that patients with AKI tend to stay in the hospital longer 
[(source)](https://link.springer.com/article/10.1007/s00467-019-04431-3).


One common cause of AKI is the medication class named  Non-steroidal anti-inflammatory drugs(NSAID). A common NSAID is Ibuprofen which is a popular over the counter pain killer. From this dataset, we will try to predict which patients on Ibuprofen will likely experience an AKI. This can be helpful information to save healthcare cost by promoting early interventions on those likely to get AKI.

## About the Data set

This  synthetic data set gives information related to patients with or without AKI that showed up to a hospital. Data set has 7 columns. Here the goal is to predict if the patient has AKI or not using a decision tree algorithm.

* Attribute Information
  +	patient_id 
      +	__Meaning__: The unique ID for a patient
      +	__Variable Type__: string
      +	__Possible values__:  any numbers from 1 to infinity
  +	gender 
      +	__Meaning__: the biological sex of the patient(male or female). 
      +	__Variable Type__: string
      +	__Possible values__:  ‘m’ or ‘f’
  +	age 
      +	__Meaning__: time since birth(years)
      +	__Variable Type__: double
      +	__Possible values__:  25 , 45, etc
  +	drug_name 
      +	__Meaning__: name of the drug
      +	__Variable Type__: string
      +	__Possible values__: ‘ibuprofen’
  +	dose_category
      +	__Meaning__: dose  strength category of the drug
      +	__Variable Type__: string
      +	__Possible values__:  ‘low’ means low dose; ‘med’ means average dose; ‘high’ means overdose
  +	daily_hydration_status
      +	__Meaning__:  How much water the person drinks daily
      +	__Variable Type__: string
      +	__Possible values__:   ‘bad’ means the person doesn’t really meet daily hydration requirements; ‘good’ means the person meets the daily hydration requirements.
  +	has_aki 
      +	__Meaning__: This is the target we are interested in predicting. 1 means the patient has Acute kidney injury (AKI). 0 means the person doesn’t have AKI
      +	__Variable Type__: integer
      +	__Possible values__:   1 or 0

# Table of Contents
1. Import Packages
2. Data load + EDA
3. Preparing ML models
4. Model in action and interpretation
5. Models evaluation
6. Conclusion


# 1) Import Packages
```{r ,warning=FALSE ,error=FALSE ,message=FALSE ,results='hide'}
library(tidyverse)
library(data.table)
library(openxlsx)
library(rpart)
library(rpart.plot)
library(caret)
```


utility function
```{r}

factorize_str <- function (dt){
  #Purpose:Temporary converts a datatable's character datatypes into factor. This way when summarize function is used, it lists out the counts of the categorical variables
  #input:(datatable)
  #output:(datatable) returns a copy of the datatable but with all the character datatypes as factors
  
  
  #Making a copy to not affect the original datatable
  dt_copy <- copy(dt)

  for (col_name in colnames(dt_copy)){
    if (is.character(dt_copy[[col_name]])){
        set(dt_copy, j = col_name, value = as.factor(dt_copy[[col_name]]))
    }
  }
  
    
  dt_copy
}
```



#2) Data load + EDA

```{r}

df <- openxlsx::read.xlsx('dataset synthetic 5.xlsx')
dt <- as.data.table(df)

head(dt)
```
```{r}
#view summary of dataset
summary(factorize_str(dt))
glimpse(dt)

```



```{r}

#check for NA and the percentage NA makes up for those columns with NA
round(colSums(is.na(dt)) * 100/nrow(dt) ,1)


#Check for duplicate patients
#Should return empty if the data is unique at patient level
dt[ ,.N , by='patient_id'][N>1] 

```

```{r}
#temporary categorical variable to aid with ggplot visualization
dt[ , has_aki_category:=fifelse(has_aki==1,'yes_aki','no_aki')]

#Temporary  column for a constant to aid with ggplot visualization
dt[ , constant:=1]

#converting to factors
dt[ , gender:= as.factor(gender)]
dt[, dose_category := factor(dose_category, levels = c('low','med','high'))]
dt[, daily_hydration_status := factor(daily_hydration_status, levels = c('bad','good'))]

```



## Graphs
```{r}

# Distribution of patients' age split by Target variable
ggplot(dt, aes(x = age , fill=has_aki_category)) + 
  geom_density(alpha = 0.5) +
  ggtitle("Age Distributions of AKI Groups") +
  theme(plot.title = element_text(hjust = 0.5))

```
<br/>
- insight: Not normally distributed. Seems like the seniors and children/young adults are more likely to suffer AKI from Ibuprofen


```{r}

# Visualize the proportion of dose categories that resulted in an event of AKI  
ggplot(dt, aes (fill=has_aki_category ,y=constant, x=dose_category)) + 
  geom_bar(position="fill", stat="identity") + 
  labs( title = "AKI Proportion Respective to Dosing Category", y = "proportions") +
  theme(plot.title = element_text(hjust = 0.5))
```
<br/>
- insight: Looks like high dose category has much higher proportion of AKI compared to low and med doses.



```{r}
# Visualize the proportion of gender category that resulted in an event of AKI  
ggplot(dt, aes (fill=has_aki_category ,y=constant, x=gender)) + 
    geom_bar(position="fill", stat="identity") + 
  labs( title = "AKI Proportion Respective to Gender Category", y = "proportions") +
  theme(plot.title = element_text(hjust = 0.5))

```
<br/>
- insight: Gender seems to have no impact on whether a patient acquires AKI




```{r}
# Visualize the proportion of hydration status that resulted in an event of AKI 
ggplot(dt, aes (fill=has_aki_category ,y=constant, x=daily_hydration_status)) + 
    geom_bar(position="fill", stat="identity") + 
  labs( title = "AKI Proportion Respective to Hydration Category", y = "proportions") +
  theme(plot.title = element_text(hjust = 0.5))
```
<br/>
- insight: Patients in the bad hydration status group has much higher proportion of AKI




#3) Preparing ML models
```{r}
#selecting relevant columns
dt_less_columns <- dt[, .(gender,age,dose_category,daily_hydration_status,has_aki)]

```

```{r}
#set seed to regenerate the same graph
set.seed(10)


#Split into training/testing
trainIndex <- createDataPartition(dt$has_aki, p = .7, 
                                  list = FALSE, 
                                  times = 1)

train_dt <- dt_less_columns[ trainIndex,]
test_dt  <- dt_less_columns[-trainIndex,]

#Check if the proportions are similiar post split
prop.table(table(train_dt$has_aki))
prop.table(table(test_dt$has_aki))
```
```{r}
head(train_dt)
```



#4) Model in action and intepretation
```{r}
#'class' for method because we are interested in classification instead of regression
fit <- rpart(has_aki ~., data = train_dt, method = 'class')
rpart.plot(fit, extra = 106)

```

```{r}
#see the rules
print(fit)
```
* insights:
  + We know that  old age is a risk factor [https://www.nhs.uk/conditions/acute-kidney-injury/]
  + Good hydration status is important to maintain fluid flow to the kidneys so that AKI doesn't happen
  + Makes sense that low dose is least likely going to lead to AKI
  + As predicted from visualizing the gender proportion graph, gender feature doesn't really help us predict if someone has AKI. That is probably why gender feature wasn't included in the tree.





#5) Models evaluation

```{r}
#prediction
predicted_results <-predict(fit, test_dt, type = 'class')
```



```{r}
#matrix table
confusion_matrix <- table(test_dt$has_aki, predicted_results)
confusion_matrix

#accuracy
accuracy_Test <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste('Accuracy for test', accuracy_Test))
```
#6) Conclusion

Exploratory data analysis showed that patients that experienced AKI are usually involved with factors like high dose Ibuprofen, old age and/or  bad daily hydration status. Gender wasn't an important factor as we seen in the graph and the exclusion of the feature in the decision tree. Overall, the accuracy of the model was 93%. Decision trees tend to over fit so we could improve the accuracy validity by tuning the parameters like the depth of the tree, minimum samples in leaf nodes , etc.

